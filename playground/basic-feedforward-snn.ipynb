{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import snntorch.functional as SF\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "data_path='/tmp/data/mnist'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_steps):\n",
    "        super().__init__()\n",
    "\n",
    "        num_inputs = 784 # number of inputs\n",
    "        num_hidden = 300 # number of hidden neurons\n",
    "        num_outputs = 10 # number of classes (i.e., output neurons)\n",
    "\n",
    "        beta1 = 0.9 # global decay rate for all leaky neurons in layer 1\n",
    "        beta2 = torch.rand((num_outputs), dtype = torch.float) # independent decay rate for each leaky neuron in layer 2: [0, 1)\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta1) # not a learnable decay rate\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta2, learn_beta=True) # learnable decay rate\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
    "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
    "        spk2_rec = [] # record output spikes\n",
    "        mem2_rec = [] # record output hidden states\n",
    "\n",
    "        for step in range(self.num_steps): # loop over time\n",
    "            cur1 = self.fc1(x.flatten(1))\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            spk2_rec.append(spk2) # record spikes\n",
    "            mem2_rec.append(mem2) # record membrane\n",
    "\n",
    "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "num_steps = 25\n",
    "net = Net(num_steps).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0 \n",
      "Train Loss: 0.10\n",
      "Accuracy: 97.66%\n",
      "\n",
      "Epoch 0, Iteration 25 \n",
      "Train Loss: 0.11\n",
      "Accuracy: 96.09%\n",
      "\n",
      "Epoch 0, Iteration 50 \n",
      "Train Loss: 0.09\n",
      "Accuracy: 96.88%\n",
      "\n",
      "Epoch 0, Iteration 75 \n",
      "Train Loss: 0.07\n",
      "Accuracy: 96.88%\n",
      "\n",
      "Epoch 0, Iteration 100 \n",
      "Train Loss: 0.06\n",
      "Accuracy: 97.66%\n",
      "\n",
      "Epoch 0, Iteration 125 \n",
      "Train Loss: 0.11\n",
      "Accuracy: 95.31%\n",
      "\n",
      "Epoch 0, Iteration 150 \n",
      "Train Loss: 0.07\n",
      "Accuracy: 98.44%\n",
      "\n",
      "Epoch 0, Iteration 175 \n",
      "Train Loss: 0.09\n",
      "Accuracy: 96.88%\n",
      "\n",
      "Epoch 0, Iteration 200 \n",
      "Train Loss: 0.11\n",
      "Accuracy: 96.09%\n",
      "\n",
      "Epoch 0, Iteration 225 \n",
      "Train Loss: 0.10\n",
      "Accuracy: 95.31%\n",
      "\n",
      "Epoch 0, Iteration 250 \n",
      "Train Loss: 0.08\n",
      "Accuracy: 97.66%\n",
      "\n",
      "Epoch 0, Iteration 275 \n",
      "Train Loss: 0.07\n",
      "Accuracy: 99.22%\n",
      "\n",
      "Epoch 0, Iteration 300 \n",
      "Train Loss: 0.12\n",
      "Accuracy: 93.75%\n",
      "\n",
      "Epoch 0, Iteration 325 \n",
      "Train Loss: 0.07\n",
      "Accuracy: 98.44%\n",
      "\n",
      "Epoch 0, Iteration 350 \n",
      "Train Loss: 0.09\n",
      "Accuracy: 95.31%\n",
      "\n",
      "Epoch 0, Iteration 375 \n",
      "Train Loss: 0.07\n",
      "Accuracy: 97.66%\n",
      "\n",
      "Epoch 0, Iteration 400 \n",
      "Train Loss: 0.09\n",
      "Accuracy: 96.88%\n",
      "\n",
      "Epoch 0, Iteration 425 \n",
      "Train Loss: 0.10\n",
      "Accuracy: 95.31%\n",
      "\n",
      "Epoch 0, Iteration 450 \n",
      "Train Loss: 0.12\n",
      "Accuracy: 95.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "num_epochs = 1 # run for 1 epoch - each data sample is seen only once\n",
    "\n",
    "loss_hist = [] # record loss over iterations\n",
    "acc_hist = [] # record accuracy over iterations\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec, _ = net(data) # forward-pass\n",
    "        loss_val = loss_fn(spk_rec, targets) # loss calculation\n",
    "        optimizer.zero_grad() # null gradients\n",
    "        loss_val.backward() # calculate gradients\n",
    "        optimizer.step() # update weights\n",
    "        loss_hist.append(loss_val.item()) # store loss\n",
    "\n",
    "        # print every 25 iterations\n",
    "        if i % 25 == 0:\n",
    "          net.eval()\n",
    "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
    "\n",
    "          # check accuracy on a single batch\n",
    "          acc = SF.accuracy_rate(spk_rec, targets)\n",
    "          acc_hist.append(acc)\n",
    "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "        # uncomment for faster termination\n",
    "        if i == 150:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decay rate of the first layer: 0.900\n",
      "\n",
      "Trained decay rates of the second layer: Parameter containing:\n",
      "tensor([0.9363, 0.7177, 0.4824, 0.8845, 0.9742, 0.4527, 0.5148, 0.7540, 0.9218,\n",
      "        0.9530], device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trained decay rate of the first layer: {net.lif1.beta:.3f}\\n\")\n",
    "\n",
    "print(f\"Trained decay rates of the second layer: {net.lif2.beta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
